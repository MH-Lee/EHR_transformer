{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed_X_visit_over3.pkl', 'rb') as f:\n",
    "    data_x = pickle.load(f)\n",
    "\n",
    "with open('../data/preprocessed_y_visit_over3.pkl', 'rb') as f: \n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_list = pickle.load(open('../new_data/top_100_list.pkl', 'rb'))\n",
    "top10_list = pickle.load(open('../new_data/top_10_list.pkl', 'rb'))\n",
    "top20_list = pickle.load(open('../new_data/top_20_list.pkl', 'rb'))\n",
    "top40_list = pickle.load(open('../new_data/top_40_list.pkl', 'rb'))\n",
    "top60_list = pickle.load(open('../new_data/top_60_list.pkl', 'rb'))\n",
    "top80_list = pickle.load(open('../new_data/top_80_list.pkl', 'rb'))\n",
    "bot10_list = pickle.load(open('../new_data/bot_10_list.pkl', 'rb'))\n",
    "bot20_list = pickle.load(open('../new_data/bot_20_list.pkl', 'rb'))\n",
    "bot40_list = pickle.load(open('../new_data/bot_40_list.pkl', 'rb'))\n",
    "bot60_list = pickle.load(open('../new_data/bot_60_list.pkl', 'rb'))\n",
    "bot80_list = pickle.load(open('../new_data/bot_80_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bot20_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultiLabelBinarizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\">?<span>Documentation for MultiLabelBinarizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultiLabelBinarizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_t100 = MultiLabelBinarizer()\n",
    "mlb_t100.fit([top100_list])\n",
    "\n",
    "mlb_t10 = MultiLabelBinarizer()\n",
    "mlb_t10.fit([top10_list])\n",
    "mlb_t20 = MultiLabelBinarizer()\n",
    "mlb_t20.fit([top20_list])\n",
    "mlb_t40 = MultiLabelBinarizer()\n",
    "mlb_t40.fit([top40_list])\n",
    "mlb_t60 = MultiLabelBinarizer()\n",
    "mlb_t60.fit([top60_list])\n",
    "mlb_t80 = MultiLabelBinarizer()\n",
    "mlb_t80.fit([top80_list])\n",
    "\n",
    "mlb_b10 = MultiLabelBinarizer()\n",
    "mlb_b10.fit([bot10_list])\n",
    "mlb_b20 = MultiLabelBinarizer()\n",
    "mlb_b20.fit([bot20_list])\n",
    "mlb_b40 = MultiLabelBinarizer()\n",
    "mlb_b40.fit([bot40_list])\n",
    "mlb_b60 = MultiLabelBinarizer()\n",
    "mlb_b60.fit([bot60_list])\n",
    "mlb_b80 = MultiLabelBinarizer()\n",
    "mlb_b80.fit([bot80_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {}\n",
    "for key, label_dict in labels.items():\n",
    "    top10_label_bin = mlb_t10.transform([label_dict['top100_label']])\n",
    "    top20_label_bin = mlb_t20.transform([label_dict['top100_label']])\n",
    "    top40_label_bin = mlb_t40.transform([label_dict['top100_label']])\n",
    "    top60_label_bin = mlb_t60.transform([label_dict['top100_label']])\n",
    "    top80_label_bin = mlb_t80.transform([label_dict['top100_label']])\n",
    "    bot10_label_bin = mlb_b10.transform([label_dict['top100_label']])\n",
    "    bot20_label_bin = mlb_b20.transform([label_dict['top100_label']])\n",
    "    bot40_label_bin = mlb_b40.transform([label_dict['top100_label']])\n",
    "    bot60_label_bin = mlb_b60.transform([label_dict['top100_label']])\n",
    "    bot80_label_bin = mlb_b80.transform([label_dict['top100_label']])\n",
    "    \n",
    "    p_label = {'origin_y': label_dict['origin_y'],\n",
    "               'top100_label': label_dict['top100_label'],\n",
    "               'top100_label_bin': label_dict['top100_label_bin'], \n",
    "               'top10_label_bin': top10_label_bin,\n",
    "               'top20_label_bin': top20_label_bin,\n",
    "               'top40_label_bin': top40_label_bin,\n",
    "               'top60_label_bin': top60_label_bin,\n",
    "               'top80_label_bin': top80_label_bin,\n",
    "               'bot10_label_bin': bot10_label_bin,\n",
    "               'bot20_label_bin': bot20_label_bin,\n",
    "               'bot40_label_bin': bot40_label_bin,\n",
    "               'bot60_label_bin': bot60_label_bin,\n",
    "               'bot80_label_bin': bot80_label_bin}\n",
    "    new_labels[key] = p_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed_y_visit_over3_new.pkl', 'wb') as f: \n",
    "    pickle.dump(new_labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_gt2t_new = {}\n",
    "for k, v in data_x.items():\n",
    "    # print(k, v)\n",
    "    visit_new = {}\n",
    "    for v_k, v_v in v.items():\n",
    "        total_list = list(set(v_v['diagnoses'])) + list(set(v_v['procedures'])) + v_v['drugs']\n",
    "        # visit_new[v_k] = v_v\n",
    "        if len(total_list) > 1:\n",
    "            visit_new[v_k] = {'diagnoses': None, 'procedures':None, 'drugs': None, 'admitdate':None}\n",
    "            visit_new[v_k]['diagnoses'] = list(set(v_v['diagnoses'])) \n",
    "            visit_new[v_k]['procedures'] = list(set(v_v['procedures'])) \n",
    "            visit_new[v_k]['drugs'] = list(set(v_v['drugs'])) \n",
    "            visit_new[v_k]['admitdate'] = v_v['admitdate']\n",
    "    visit_gt2t_new[k] = visit_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = pd.read_csv('../data/admissions.csv.gz', compression='gzip', usecols=['subject_id', 'hadm_id', 'admittime', 'admission_type', 'race'])\n",
    "patients = pd.read_csv('../data/patients.csv')\n",
    "patients = patients[['subject_id', 'gender','anchor_age','anchor_year']]\n",
    "patients['yob']= patients['anchor_year'] - patients['anchor_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_gt2t_last = {}\n",
    "for k, v in visit_gt2t_new.items():\n",
    "    # break\n",
    "    if len(v) >= 2:\n",
    "        visit_gt2t_last[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drug selection\n",
    "dr_list = list()\n",
    "dr_length = list()\n",
    "for k, visit in visit_gt2t_new.items():\n",
    "    for v_id, v in visit.items():\n",
    "        dr_list.extend(v['drugs'])\n",
    "        dr_length.append(len(v['drugs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dr_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dict = dict(Counter(dr_list))\n",
    "sorted_drug_dict = dict(sorted(drug_dict.items(), key=lambda item: item[1], reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43096/43096 [05:59<00:00, 119.85it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "rm_patient_num =0\n",
    "rm_patient_list = []\n",
    "\n",
    "for p_id, v_data in tqdm(visit_gt2t_last.items()):\n",
    "    visit_data = {'seq': [], 'data':[], 'time': [], 'diagnoses_top100': [], 'diagnoses_top100_len':[],\n",
    "                  'gender': patients.loc[patients['subject_id'] == p_id, 'gender'].unique()[0],\n",
    "                  'race': adm.loc[adm['subject_id'] == p_id, 'race'].unique()[0]}\n",
    "    seg_idx = 0\n",
    "    for v_id, record in v_data.items():\n",
    "        record['visit_id'] = v_id\n",
    "        record['admission_type'] = adm.loc[(adm['subject_id'] == p_id) & (adm['hadm_id'] == v_id), 'admission_type'].values[0]\n",
    "        dt_obj = datetime.strptime(record['admitdate'], '%Y-%m-%d')\n",
    "        age_at_adm = dt_obj.year - patients.loc[patients['subject_id'] == p_id, 'yob'].values[0]\n",
    "        if age_at_adm < 0:\n",
    "            age_at_adm = 90\n",
    "        record['age'] = age_at_adm\n",
    "        if len(record['drugs']) > 50:\n",
    "            ## 약물 코드가 50개 이상이면 빈도수 기준 50개만 선택\n",
    "            sorted_drugs = sorted(sorted_drug_dict, key=sorted_drug_dict.get, reverse=True)\n",
    "            top100_drugs = [elem for elem in sorted_drugs if elem in record['drugs']][:50]\n",
    "            seq_data = record['diagnoses'] + record['procedures'] + top100_drugs\n",
    "        else:\n",
    "            seq_data = record['diagnoses'] + record['procedures'] + record['drugs']\n",
    "        \n",
    "        top100_diagnoses = [d_code for d_code in record['diagnoses'] if d_code in top100_list]\n",
    "        visit_data['diagnoses_top100'].append(top100_diagnoses)\n",
    "        visit_data['diagnoses_top100_len'].append(len(top100_diagnoses))\n",
    "        visit_data['seq'].append(seq_data)\n",
    "        visit_data['data'].append(record)\n",
    "        visit_data['time'].append(dt_obj)\n",
    "        \n",
    "    if 0 in visit_data['diagnoses_top100_len']:\n",
    "        rm_patient_num += 1\n",
    "        rm_patient_list.append(p_id)\n",
    "        continue\n",
    "    \n",
    "    td_list = [(visit_data['time'][-1]- dt).days for dt in visit_data['time']]\n",
    "    visit_data['timedelta'] = td_list\n",
    "    visit_data['labels_origin'] = labels[p_id]['top100_label']\n",
    "    visit_data['labels_top100_bin'] = labels[p_id]['top100_label_bin']\n",
    "    visit_data['labels_top10_bin'] = labels[p_id]['top10_label_bin']\n",
    "    visit_data['labels_top20_bin'] = labels[p_id]['top20_label_bin']\n",
    "    visit_data['labels_top40_bin'] = labels[p_id]['top40_label_bin']\n",
    "    visit_data['labels_top60_bin'] = labels[p_id]['top60_label_bin']\n",
    "    visit_data['labels_top80_bin'] = labels[p_id]['top80_label_bin']\n",
    "    visit_data['labels_bot10_bin'] = labels[p_id]['bot10_label_bin']\n",
    "    visit_data['labels_bot20_bin'] = labels[p_id]['bot20_label_bin']\n",
    "    visit_data['labels_bot40_bin'] = labels[p_id]['bot40_label_bin']\n",
    "    visit_data['labels_bot60_bin'] = labels[p_id]['bot60_label_bin']\n",
    "    visit_data['labels_bot80_bin'] = labels[p_id]['bot80_label_bin']\n",
    "    data_dict[p_id] = visit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/data4pretrained_filter_drugs_add_multi_bin.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/data4pretrained_filter_drugs_add_multi_bin.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = list()\n",
    "p_list = list()\n",
    "dr_list = list()\n",
    "for k, visit in data_dict.items():\n",
    "    for v in visit['data']:\n",
    "        d_list.extend(v['diagnoses'])\n",
    "        p_list.extend(v['procedures'])\n",
    "        dr_list.extend(v['drugs'])\n",
    "        \n",
    "d_list = list(set(d_list))\n",
    "p_list = list(set(p_list))\n",
    "dr_list = list(set(dr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863, 738, 3487)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_list), len(p_list), len(dr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2idx = {'padding':0}\n",
    "\n",
    "idx = 1\n",
    "for d in d_list:\n",
    "    code2idx[d] = idx\n",
    "    idx += 1\n",
    "\n",
    "for p in p_list:\n",
    "    code2idx[p] = idx\n",
    "    idx += 1\n",
    "\n",
    "dr_idx = 1\n",
    "for dr in dr_list:  \n",
    "    code2idx[dr] = idx\n",
    "    idx += 1\n",
    "\n",
    "code2idx['[CLS]'] = idx\n",
    "code2idx['[SEP]'] = idx + 1\n",
    "code2idx['[MASK]'] = idx + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5092"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5091"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2idx['[MASK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/code_indices/code_dict_pretrained.pkl', 'wb') as f:\n",
    "    pickle.dump(code2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/code_indices/code_dict_pretrained.pkl', 'rb') as f:\n",
    "    code2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_idx = data_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39802/39802 [00:05<00:00, 6773.33it/s] \n"
     ]
    }
   ],
   "source": [
    "for k, visit in tqdm(data_dict_idx.items()):\n",
    "    visit['seq_idx'] = [list(map(code2idx.get, v)) for v in visit['seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, visit in tqdm(data_dict_idx.items()):\n",
    "#     visit['total_seq_idx'] = list(map(code2idx.get, visit['total_seq']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39802/39802 [00:00<00:00, 50188.31it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dict_new= dict()\n",
    "rm_patient_num =0\n",
    "rm_patient_list = []\n",
    "for p_id in tqdm(list(data_dict_idx.keys())):\n",
    "    p_data = {'visit':[], 'visit_idx': [], 'visit_length':0, 'age': [], 'gender': None, 'race': None, 'admission_type': [], \\\n",
    "              'diagnoses_top100': None, 'diagnoses_top100_len': None, 'seq':None, 'seq_idx':None, 'timedelta': None, 'label':[]}\n",
    "    \n",
    "    for v_id, v_data in enumerate(data_dict_idx[p_id]['data']):            \n",
    "        p_data['visit'].append(v_data['visit_id'])\n",
    "        p_data['visit_idx'].append(v_id)\n",
    "        p_data['seq'] = data_dict_idx[p_id]['seq']\n",
    "        p_data['seq_idx'] = data_dict_idx[p_id]['seq_idx']\n",
    "        p_data['time'] = data_dict_idx[p_id]['time']\n",
    "        p_data['timedelta'] = data_dict_idx[p_id]['timedelta']\n",
    "        p_data['age'].append(v_data['age'])\n",
    "        p_data['admission_type'].append(v_data['admission_type'])\n",
    "    \n",
    "    p_data['diagnoses_top100'] = data_dict_idx[p_id]['diagnoses_top100']\n",
    "    p_data['diagnoses_top100_len'] = data_dict_idx[p_id]['diagnoses_top100_len']\n",
    "    assert len(p_data['diagnoses_top100']) == len(p_data['diagnoses_top100_len']) == len(p_data['visit'])\n",
    "    p_data['race'] = data_dict_idx[p_id]['race']\n",
    "    p_data['gender'] = data_dict_idx[p_id]['gender']\n",
    "    p_data['label_top100'] = np.squeeze(data_dict_idx[p_id]['labels_top100_bin'])\n",
    "    p_data['label_top10'] = np.squeeze(data_dict_idx[p_id]['labels_top10_bin'])\n",
    "    p_data['label_top20'] = np.squeeze(data_dict_idx[p_id]['labels_top20_bin'])\n",
    "    p_data['label_top40'] = np.squeeze(data_dict_idx[p_id]['labels_top40_bin'])\n",
    "    p_data['label_top60'] = np.squeeze(data_dict_idx[p_id]['labels_top60_bin'])\n",
    "    p_data['label_top80'] = np.squeeze(data_dict_idx[p_id]['labels_top80_bin'])\n",
    "    p_data['label_bot10'] = np.squeeze(data_dict_idx[p_id]['labels_bot10_bin'])\n",
    "    p_data['label_bot20'] = np.squeeze(data_dict_idx[p_id]['labels_bot20_bin'])\n",
    "    p_data['label_bot40'] = np.squeeze(data_dict_idx[p_id]['labels_bot40_bin'])\n",
    "    p_data['label_bot60'] = np.squeeze(data_dict_idx[p_id]['labels_bot60_bin'])\n",
    "    p_data['label_bot80'] = np.squeeze(data_dict_idx[p_id]['labels_bot80_bin'])\n",
    "    data_dict_new[p_id] = p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/data4pretrained_filter_drugs_preprocess_add_multibin.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict_new, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/data4pretrained_filter_drugs_preprocess_add_multibin.pkl', 'rb') as f:\n",
    "    data_dict_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39802"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10123949 55\n",
      "10264646 76\n",
      "10577647 78\n",
      "10578325 67\n",
      "10580201 59\n",
      "10714009 113\n",
      "10913302 64\n",
      "11021643 63\n",
      "11296936 76\n",
      "11553072 69\n",
      "11582633 81\n",
      "11714071 62\n",
      "11761621 56\n",
      "11818101 64\n",
      "11890447 66\n",
      "12251785 79\n",
      "12468016 88\n",
      "12547294 69\n",
      "12563258 60\n",
      "12596559 63\n",
      "13166511 53\n",
      "13297743 91\n",
      "13470788 52\n",
      "13475033 96\n",
      "13877234 60\n",
      "13999829 54\n",
      "14029474 52\n",
      "14394983 124\n",
      "15084163 53\n",
      "15107347 51\n",
      "15108590 52\n",
      "15114531 67\n",
      "15229574 79\n",
      "15464144 75\n",
      "15496609 133\n",
      "15935768 56\n",
      "16124481 62\n",
      "16233333 67\n",
      "16439884 58\n",
      "16615356 55\n",
      "16662316 129\n",
      "16675371 66\n",
      "16809525 57\n",
      "16924675 54\n",
      "17011846 56\n",
      "17051420 54\n",
      "17204468 59\n",
      "17340686 51\n",
      "17477304 51\n",
      "17517983 94\n",
      "17716210 80\n",
      "17937834 61\n",
      "18001923 69\n",
      "18284271 82\n",
      "18376342 52\n",
      "18553055 55\n",
      "18655830 69\n",
      "18676703 59\n",
      "18970086 68\n",
      "19127408 51\n",
      "19610016 52\n",
      "19713100 62\n",
      "19759225 63\n",
      "19921471 57\n"
     ]
    }
   ],
   "source": [
    "data_dict_max50 = dict()\n",
    "for p_id , data in data_dict_new.items():\n",
    "    new_data = dict()\n",
    "    if len(data['visit']) > 50:\n",
    "        print(p_id, len(data['visit']))\n",
    "        new_visit_idx = [i for i in range(len(data['visit_idx'][-50:]))]\n",
    "    else:\n",
    "        new_visit_idx = data['visit_idx']\n",
    "    new_data['visit'] = data['visit'][-50:]\n",
    "    new_data['visit_idx'] = new_visit_idx\n",
    "    new_data['visit_length'] = len(data['visit'][-50:])\n",
    "    new_data['seq'] = data['seq'][-50:]\n",
    "    new_data['seq_idx'] = data['seq_idx'][-50:]\n",
    "    new_data['time'] = data['time'][-50:]\n",
    "    new_data['timedelta'] = data['timedelta'][-50:]\n",
    "    new_data['age'] = data['age'][-50:]\n",
    "    new_data['diagnoses_top100'] = data['diagnoses_top100'][-50:]\n",
    "    new_data['diagnoses_top100_len'] = data['diagnoses_top100_len'][-50:]\n",
    "    assert len(data['visit_idx'][-50:]) == len(data['seq'][-50:]) == len(data['age'][-50:]) == len(data['diagnoses_top100'][-50:])\n",
    "    new_data['gender'] = data['gender']\n",
    "    new_data['race'] = data['race']\n",
    "    new_data['label_top100'] = data['label_top100']\n",
    "    new_data['label_top10'] = data['label_top10']\n",
    "    new_data['label_top20'] = data['label_top20']\n",
    "    new_data['label_top40'] = data['label_top40']\n",
    "    new_data['label_top60'] = data['label_top60']\n",
    "    new_data['label_top80'] = data['label_top80']\n",
    "    new_data['label_bot10'] = data['label_bot10']\n",
    "    new_data['label_bot20'] = data['label_bot20']\n",
    "    new_data['label_bot40'] = data['label_bot40']\n",
    "    new_data['label_bot60'] = data['label_bot60']\n",
    "    new_data['label_bot80'] = data['label_bot80']\n",
    "    data_dict_max50[p_id] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/data4pretrained_filter_drugs_preprocess_add_multibin_maxlen50.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict_max50, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/data4pretrained_filter_drugs_preprocess_add_multibin_maxlen50.pkl', 'rb') as f:\n",
    "    data_dict_max50 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39802"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict_max50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_code_type(code):\n",
    "    if code.startswith('d'):\n",
    "        return 1\n",
    "    elif code.startswith('pcs'):\n",
    "        return 2\n",
    "    elif code.startswith('p_'):\n",
    "        return 3\n",
    "    elif code in ['[CLS]', '[SEP]']:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [123, 321, 666, 777, 5959]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_patient_list = list(data_dict_max50.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seed in seed_list:\n",
    "#     train_indices, test_indices = train_test_split(total_patient_list, test_size=0.1, random_state=seed)\n",
    "#     train_indices, val_indices = train_test_split(train_indices, test_size=len(test_indices), random_state=seed)\n",
    "#     print(len(train_indices), len(val_indices), len(test_indices))\n",
    "#     with open(f'../new_data/split_indices/train_indices_{seed}.pkl', 'wb') as f:\n",
    "#         pickle.dump(train_indices, f)\n",
    "#     with open(f'../new_data/split_indices/val_indices_{seed}.pkl', 'wb') as f:\n",
    "#         pickle.dump(val_indices, f)\n",
    "#     with open(f'../new_data/split_indices/test_indices_{seed}.pkl', 'wb') as f:\n",
    "#         pickle.dump(test_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31840/31840 [00:34<00:00, 930.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31840/31840 [00:35<00:00, 902.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31840/31840 [00:29<00:00, 1062.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31840/31840 [00:34<00:00, 920.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31840/31840 [00:35<00:00, 901.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    }
   ],
   "source": [
    "for seed in seed_list:\n",
    "    with open(f'../new_data/split_indices/train_indices_{seed}.pkl', 'rb') as f:\n",
    "        train_indices = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    total_len_list = []\n",
    "    train_datasets = dict()\n",
    "    for p_id in tqdm(train_indices):\n",
    "        data = data_dict_max50[p_id]\n",
    "        if len(data['visit']) > slide_length:\n",
    "            for i in range(len(data['visit']) - slide_length + 1):\n",
    "                visit_data = dict()\n",
    "                visit_data['patient_id'] = p_id\n",
    "                visit_data['visit'] = data['visit'][i:i+slide_length]\n",
    "                visit_data['visit_idx'] = data['visit_idx'][i:i+slide_length]\n",
    "                visit_data['visit_length'] = len(data['visit'][i:i+slide_length])\n",
    "                \n",
    "                slide_seq = data['seq'][i:i+slide_length]\n",
    "                slide_seq_idx = data['seq_idx'][i:i+slide_length]\n",
    "                \n",
    "                total_seq = ['[CLS]'] + [item for sublist in slide_seq for item in sublist + ['[SEP]']]\n",
    "                total_seq_idx = [code2idx['[CLS]']] + [item for sublist in slide_seq_idx for item in sublist + [code2idx['[SEP]']]]\n",
    "                total_code_type = list(map(convert_code_type, total_seq))\n",
    "                total_vis_seg = [visit_data['visit_idx'][0]] + [elem for idx, v_idx in enumerate(visit_data['visit_idx']) for elem in [v_idx] * len(slide_seq_idx[idx]) + [v_idx]]\n",
    "                assert len(total_seq) == len(total_seq_idx) == len(total_code_type) == len(total_vis_seg)\n",
    "                \n",
    "                visit_data['total_seq'] = total_seq\n",
    "                visit_data['total_seq_idx'] = total_seq_idx\n",
    "                visit_data['code_type'] = total_code_type\n",
    "                visit_data['visit_seg'] = total_vis_seg\n",
    "                visit_data['total_len'] = len(total_seq)\n",
    "                visit_data['time'] = data['time'][i:i+slide_length]\n",
    "\n",
    "                timedelta_replacement = {visit_data['visit_idx'][idx]: td for idx, td in enumerate(data['timedelta'][i:i+slide_length])}\n",
    "                visit_data['timedelta'] = [timedelta_replacement[val] for val in total_vis_seg]\n",
    "                timevec_replacement = {visit_data['visit_idx'][idx]: [tm.year, tm.month, tm.day, tm.isocalendar().week] \\\n",
    "                                    for idx, tm in enumerate(data['time'][i:i+slide_length])}\n",
    "                visit_data['timevec'] = [timevec_replacement[val] for val in total_vis_seg]\n",
    "                if i == len(data['visit']) - slide_length :\n",
    "                    visit_data['label_top10'] = data['label_top10']\n",
    "                    visit_data['label_top20'] = data['label_top20']\n",
    "                    visit_data['label_top40'] = data['label_top40']\n",
    "                    visit_data['label_top60'] = data['label_top60']\n",
    "                    visit_data['label_top80'] = data['label_top80']\n",
    "                    visit_data['label_top100'] = data['label_top100']\n",
    "                    visit_data['label_bot10'] = data['label_bot10']\n",
    "                    visit_data['label_bot20'] = data['label_bot20']\n",
    "                    visit_data['label_bot40'] = data['label_bot40']\n",
    "                    visit_data['label_bot60'] = data['label_bot60']\n",
    "                    visit_data['label_bot80'] = data['label_bot80']\n",
    "                    visit_data['label_visit_idx'] = data['visit_idx'][-1] + 1\n",
    "                else:\n",
    "                    visit_data['label_top10'] = mlb_t10.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_top20'] = mlb_t20.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_top40'] = mlb_t40.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_top60'] = mlb_t60.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_top80'] = mlb_t80.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_top100'] = mlb_t100.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_bot10'] = mlb_b10.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_bot20'] = mlb_b20.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_bot40'] = mlb_b40.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_bot60'] = mlb_b60.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_bot80'] = mlb_b80.transform([data['diagnoses_top100'][i+slide_length]])[0]\n",
    "                    visit_data['label_visit_idx'] = data['visit_idx'][i+slide_length]\n",
    "                train_datasets[f'{str(p_id)}_slide{str(i)}'] = visit_data\n",
    "        else:\n",
    "            visit_data = dict()\n",
    "            visit_data['patient_id'] = p_id\n",
    "            visit_data['visit'] = data['visit']\n",
    "            visit_data['visit_idx'] = data['visit_idx']\n",
    "            visit_data['visit_length'] = data['visit_length']\n",
    "            \n",
    "            total_seq = ['[CLS]'] + [item for sublist in data['seq'] for item in sublist + ['[SEP]']]\n",
    "            total_seq_idx = [code2idx['[CLS]']] + [item for sublist in data['seq_idx'] for item in sublist + [code2idx['[SEP]']]]\n",
    "            total_code_type = list(map(convert_code_type, total_seq))\n",
    "            total_vis_seg = [data['visit_idx'][0]] + [elem for idx, v_idx in enumerate(data['visit_idx']) for elem in [v_idx] * len(data['seq_idx'][idx]) + [v_idx]]\n",
    "            assert len(total_seq) == len(total_seq_idx) == len(total_code_type) == len(total_vis_seg)\n",
    "            \n",
    "            visit_data['total_seq'] = total_seq\n",
    "            visit_data['total_seq_idx'] = total_seq_idx\n",
    "            visit_data['code_type'] = total_code_type\n",
    "            visit_data['visit_seg'] = total_vis_seg\n",
    "            visit_data['total_len'] = len(total_seq)\n",
    "            visit_data['time'] = data['time']\n",
    "            \n",
    "            timedelta_replacement = {visit_data['visit_idx'][idx]: td for idx, td in enumerate(data['timedelta'])}\n",
    "            visit_data['timedelta'] = [timedelta_replacement[val] for val in total_vis_seg]\n",
    "            timevec_replacement = {visit_data['visit_idx'][idx]: [tm.year, tm.month, tm.day, tm.isocalendar().week] \\\n",
    "                                for idx, tm in enumerate(data['time'])}\n",
    "            visit_data['timevec'] = [timevec_replacement[val] for val in total_vis_seg]\n",
    "            \n",
    "            visit_data['label_top10'] = data['label_top10']\n",
    "            visit_data['label_top20'] = data['label_top20']\n",
    "            visit_data['label_top40'] = data['label_top40']\n",
    "            visit_data['label_top60'] = data['label_top60']\n",
    "            visit_data['label_top80'] = data['label_top80']\n",
    "            visit_data['label_top100'] = data['label_top100']\n",
    "            visit_data['label_bot10'] = data['label_bot10']\n",
    "            visit_data['label_bot20'] = data['label_bot20']\n",
    "            visit_data['label_bot40'] = data['label_bot40']\n",
    "            visit_data['label_bot60'] = data['label_bot60']\n",
    "            visit_data['label_bot80'] = data['label_bot80']\n",
    "\n",
    "            visit_data['label_visit_idx'] = data['visit_idx'][-1] + 1\n",
    "            train_datasets[f'{str(p_id)}_slide{str(0)}'] = visit_data\n",
    "            \n",
    "        total_len_list.append(len(total_seq))\n",
    "    \n",
    "    print(max(total_len_list))\n",
    "    with open(f'../new_data/split_datasets/train_datasets_{seed}_multi_labels.pkl', 'wb') as f:\n",
    "        pickle.dump(train_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['visit', 'visit_idx', 'visit_length', 'seq', 'seq_idx', 'time', 'timedelta', 'age', 'diagnoses_top100', 'diagnoses_top100_len', 'gender', 'race', 'label_top100', 'label_top10', 'label_top20', 'label_top40', 'label_top60', 'label_top80', 'label_bot10', 'label_bot20', 'label_bot40', 'label_bot60', 'label_bot80'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10668.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10696.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 11019.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10793.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10914.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "for seed in seed_list:\n",
    "    with open(f'../new_data/split_indices/val_indices_{seed}.pkl', 'rb') as f:\n",
    "        val_indices = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    total_len_list = []\n",
    "    valid_datasets = dict()\n",
    "    for p_id in tqdm(val_indices):\n",
    "        data = data_dict_max50[p_id]\n",
    "        visit_data = dict()\n",
    "        visit_data['patient_id'] = p_id\n",
    "        visit_data['visit'] = data['visit'][-slide_length:]\n",
    "        visit_data['visit_idx'] = data['visit_idx'][-slide_length:]\n",
    "        visit_data['visit_length'] = len(data['visit'][-slide_length:])\n",
    "\n",
    "        slide_seq = data['seq'][-slide_length:]\n",
    "        slide_seq_idx = data['seq_idx'][-slide_length:]\n",
    "\n",
    "        total_seq = ['[CLS]'] + [item for sublist in slide_seq for item in sublist + ['[SEP]']]\n",
    "        total_seq_idx = [code2idx['[CLS]']] + [item for sublist in slide_seq_idx for item in sublist + [code2idx['[SEP]']]]\n",
    "        total_code_type = list(map(convert_code_type, total_seq))\n",
    "        total_vis_seg = [visit_data['visit_idx'][0]] + [elem for idx, v_idx in enumerate(visit_data['visit_idx']) for elem in [v_idx] * len(slide_seq_idx[idx]) + [v_idx]]\n",
    "        assert len(total_seq) == len(total_seq_idx) == len(total_code_type) == len(total_vis_seg)\n",
    "\n",
    "        visit_data['total_seq'] = total_seq\n",
    "        visit_data['total_seq_idx'] = total_seq_idx\n",
    "        visit_data['code_type'] = total_code_type\n",
    "        visit_data['visit_seg'] = total_vis_seg\n",
    "        visit_data['total_len'] = len(total_seq)\n",
    "        visit_data['time'] = data['time'][-slide_length:]\n",
    "\n",
    "        timedelta_replacement = {visit_data['visit_idx'][idx]: td for idx, td in enumerate(data['timedelta'][-slide_length:])}\n",
    "        visit_data['timedelta'] = [timedelta_replacement[val] for val in total_vis_seg]\n",
    "        timevec_replacement = {visit_data['visit_idx'][idx]: [tm.year, tm.month, tm.day, tm.isocalendar().week] \\\n",
    "                            for idx, tm in enumerate(data['time'][-slide_length:])}\n",
    "        visit_data['timevec'] = [timevec_replacement[val] for val in total_vis_seg]\n",
    "        # visit_data['label'] = data['label']\n",
    "        \n",
    "        visit_data['label_top10'] = data['label_top10']\n",
    "        visit_data['label_top20'] = data['label_top20']\n",
    "        visit_data['label_top40'] = data['label_top40']\n",
    "        visit_data['label_top60'] = data['label_top60']\n",
    "        visit_data['label_top80'] = data['label_top80']\n",
    "        visit_data['label_top100'] = data['label_top100']\n",
    "        visit_data['label_bot10'] = data['label_bot10']\n",
    "        visit_data['label_bot20'] = data['label_bot20']\n",
    "        visit_data['label_bot40'] = data['label_bot40']\n",
    "        visit_data['label_bot60'] = data['label_bot60']\n",
    "        visit_data['label_bot80'] = data['label_bot80']\n",
    "        \n",
    "        visit_data['label_visit_idx'] = data['visit_idx'][-1] + 1\n",
    "        valid_datasets[f'{str(p_id)}_slide{str(0)}'] = visit_data\n",
    "        total_len_list.append(len(total_seq))\n",
    "    print(max(total_len_list))\n",
    "    with open(f'../new_data/split_datasets/valid_datasets_{seed}_multi_labels.pkl', 'wb') as f:\n",
    "        pickle.dump(valid_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10991.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10899.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 11046.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 11026.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [00:00<00:00, 10797.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    }
   ],
   "source": [
    "for seed in seed_list:\n",
    "    with open(f'../new_data/split_indices/test_indices_{seed}.pkl', 'rb') as f:\n",
    "        test_indices = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    total_len_list = []\n",
    "    test_datasets = dict()\n",
    "    for p_id in tqdm(test_indices):\n",
    "        data = data_dict_max50[p_id]\n",
    "        visit_data = dict()\n",
    "        visit_data['patient_id'] = p_id\n",
    "        visit_data['visit'] = data['visit'][-slide_length:]\n",
    "        visit_data['visit_idx'] = data['visit_idx'][-slide_length:]\n",
    "        visit_data['visit_length'] = len(data['visit'][-slide_length:])\n",
    "\n",
    "        slide_seq = data['seq'][-slide_length:]\n",
    "        slide_seq_idx = data['seq_idx'][-slide_length:]\n",
    "\n",
    "        total_seq = ['[CLS]'] + [item for sublist in slide_seq for item in sublist + ['[SEP]']]\n",
    "        total_seq_idx = [code2idx['[CLS]']] + [item for sublist in slide_seq_idx for item in sublist + [code2idx['[SEP]']]]\n",
    "        total_code_type = list(map(convert_code_type, total_seq))\n",
    "        total_vis_seg = [visit_data['visit_idx'][0]] + [elem for idx, v_idx in enumerate(visit_data['visit_idx']) for elem in [v_idx] * len(slide_seq_idx[idx]) + [v_idx]]\n",
    "        assert len(total_seq) == len(total_seq_idx) == len(total_code_type) == len(total_vis_seg)\n",
    "\n",
    "        visit_data['total_seq'] = total_seq\n",
    "        visit_data['total_seq_idx'] = total_seq_idx\n",
    "        visit_data['code_type'] = total_code_type\n",
    "        visit_data['visit_seg'] = total_vis_seg\n",
    "        visit_data['total_len'] = len(total_seq)\n",
    "        visit_data['time'] = data['time'][-slide_length:]\n",
    "\n",
    "        timedelta_replacement = {visit_data['visit_idx'][idx]: td for idx, td in enumerate(data['timedelta'][-slide_length:])}\n",
    "        visit_data['timedelta'] = [timedelta_replacement[val] for val in total_vis_seg]\n",
    "        timevec_replacement = {visit_data['visit_idx'][idx]: [tm.year, tm.month, tm.day, tm.isocalendar().week] \\\n",
    "                            for idx, tm in enumerate(data['time'][-slide_length:])}\n",
    "        visit_data['timevec'] = [timevec_replacement[val] for val in total_vis_seg]\n",
    "        # visit_data['label'] = data['label']\n",
    "        \n",
    "        visit_data['label_top10'] = data['label_top10']\n",
    "        visit_data['label_top20'] = data['label_top20']\n",
    "        visit_data['label_top40'] = data['label_top40']\n",
    "        visit_data['label_top60'] = data['label_top60']\n",
    "        visit_data['label_top80'] = data['label_top80']\n",
    "        visit_data['label_top100'] = data['label_top100']\n",
    "        visit_data['label_bot10'] = data['label_bot10']\n",
    "        visit_data['label_bot20'] = data['label_bot20']\n",
    "        visit_data['label_bot40'] = data['label_bot40']\n",
    "        visit_data['label_bot60'] = data['label_bot60']\n",
    "        visit_data['label_bot80'] = data['label_bot80']\n",
    "        visit_data['label_visit_idx'] = data['visit_idx'][-1] + 1\n",
    "        \n",
    "        test_datasets[f'{str(p_id)}_slide{str(0)}'] = visit_data\n",
    "        total_len_list.append(len(total_seq))\n",
    "        \n",
    "    print(max(total_len_list))\n",
    "    with open(f'../new_data/split_datasets/test_datasets_{seed}_multi_labels.pkl', 'wb') as f:\n",
    "        pickle.dump(test_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(total_len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5088"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "863 + 738 + 3487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
