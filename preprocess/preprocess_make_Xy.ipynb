{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/raw_data/mimiciv_X_data.pkl', 'rb') as f:\n",
    "    mimic_x_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../new_data/raw_data/mimiciv_y_label.pkl', 'rb') as f:\n",
    "    mimic_y_label = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = list()\n",
    "p_list = list()\n",
    "dr_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79421/79421 [00:00<00:00, 2668277.90it/s]\n",
      "100%|██████████| 79421/79421 [00:05<00:00, 13927.62it/s]\n"
     ]
    }
   ],
   "source": [
    "new_dict = dict()\n",
    "for p_key in tqdm(list(mimic_x_data.keys())):\n",
    "    new_dict[p_key] = None\n",
    "new_y_dict = dict()\n",
    "\n",
    "for p_key in tqdm(list(mimic_x_data.keys())):\n",
    "    p_dict = dict()\n",
    "    for v_key in mimic_x_data[p_key].keys():\n",
    "        d_code = [d_seq[0:5] for d_seq in mimic_x_data[p_key][v_key]['diagnoses'] if 'E' not in d_seq]\n",
    "        d_code = [d_seq for d_seq in d_code if 'V' not in d_seq ]\n",
    "        p_code = [p_seq[0:7] for p_seq in mimic_x_data[p_key][v_key]['procedures']]        \n",
    "        dr_code = mimic_x_data[p_key][v_key]['drugs']\n",
    "        d_list.extend(d_code)\n",
    "        p_list.extend(p_code)\n",
    "        dr_list.extend(dr_code)\n",
    "        admitdate = mimic_x_data[p_key][v_key]['admitdate']\n",
    "        visit_dict = {'diagnoses': d_code, 'procedures': p_code, 'drugs':dr_code, 'admitdate':admitdate}\n",
    "        p_dict[v_key] = visit_dict \n",
    "    label_list = [d_seq[0:5] for d_seq in mimic_y_label[p_key] if 'E' not in d_seq]\n",
    "    label_list = [d_seq for d_seq in label_list if 'V' not in d_seq ]\n",
    "    new_dict[p_key] = p_dict\n",
    "    new_y_dict[p_key] = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_over_3 = []\n",
    "for p_key in new_dict.keys():\n",
    "    if len(new_dict[p_key]) > 1:\n",
    "        visit_over_3.append(p_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43814"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visit_over_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict_over3 = dict()\n",
    "for p_key in visit_over_3:\n",
    "    total_dict_over3[p_key] = new_dict[p_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict_over3_y = dict()\n",
    "for p_key in visit_over_3:\n",
    "    total_dict_over3_y[p_key] = new_y_dict[p_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = list()\n",
    "p_list = list()\n",
    "dr_list = list()\n",
    "total_dict = dict()\n",
    "for p_key in tqdm(list(total_dict_over3.keys())):\n",
    "    total_seq = []\n",
    "    date_list = []\n",
    "    for v_key in total_dict_over3[p_key].keys():\n",
    "        d_code = total_dict_over3[p_key][v_key]['diagnoses']\n",
    "        p_code = total_dict_over3[p_key][v_key]['procedures']\n",
    "        dr_code = total_dict_over3[p_key][v_key]['drugs']\n",
    "        d_list.extend(d_code)\n",
    "        p_list.extend(p_code)\n",
    "        dr_list.extend(dr_code)\n",
    "        \n",
    "unique_d_list = list(set(d_list))\n",
    "unique_p_list = list(set(p_list))\n",
    "unique_dr_list = list(set(dr_list))\n",
    "unique_d_list = sorted(unique_d_list)\n",
    "unique_p_list = sorted(unique_p_list)\n",
    "unique_dr_list = sorted(unique_dr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_dr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_counter = dict(Counter(d_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_top100 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_top10 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[:10]\n",
    "d_bot10 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[90:]\n",
    "\n",
    "d_top20 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[:20]\n",
    "d_bot20 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[80:]\n",
    "\n",
    "d_top40 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[:40]\n",
    "d_bot40 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[60:]\n",
    "\n",
    "d_top60 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[:60]\n",
    "d_bot60 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[40:]\n",
    "\n",
    "d_top80 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[:80]\n",
    "d_bot80 = sorted(d_counter, key=lambda x:d_counter[x], reverse=True)[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./top_10_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_top10, f)\n",
    "f.close()\n",
    "\n",
    "with open('./bot_10_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_bot10, f)\n",
    "f.close()\n",
    "    \n",
    "with open('./top_20_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_top20, f)\n",
    "f.close()\n",
    "\n",
    "with open('./bot_20_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_bot20, f)\n",
    "f.close()\n",
    "\n",
    "with open('./top_40_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_top40, f)\n",
    "f.close()\n",
    "\n",
    "with open('./bot_40_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_bot40, f)\n",
    "f.close()\n",
    "\n",
    "with open('./top_60_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_top60, f)\n",
    "f.close()\n",
    "\n",
    "with open('./bot_60_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_bot60, f)\n",
    "f.close()\n",
    "\n",
    "with open('./top_80_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_top80, f)\n",
    "f.close()\n",
    "\n",
    "with open('./bot_80_list.pkl', 'wb') as f:\n",
    "    pickle.dump(d_bot80, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([d_top100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_y_dict = dict()\n",
    "for p_key in tqdm(total_dict_over3_y.keys()):\n",
    "    save_y_dict[p_key] = None\n",
    "\n",
    "for p_key in tqdm(total_dict_over3_y.keys()):\n",
    "    total_labels = total_dict_over3_y[p_key]\n",
    "    top100_list = list()\n",
    "    for tl in total_labels:\n",
    "        if tl in d_top100:\n",
    "            top100_list.append(tl)\n",
    "    save_y_dict[p_key] = {'top100_label': top100_list, 'top100_label_bin': mlb.transform([top100_list]), 'origin_y': total_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zero_p = []\n",
    "for p_key in tqdm(save_y_dict.keys()):\n",
    "    top100_label = save_y_dict[p_key]['top100_label']\n",
    "    if len(top100_label) == 0:\n",
    "        all_zero_p.append(p_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_emb = np.empty(shape=(0, 100))\n",
    "for p_key in tqdm(save_y_dict.keys()):\n",
    "    label_emb = np.vstack((label_emb, save_y_dict[p_key]['top100_label_bin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./mimic-iv-data-nd/preprocessed_X_visit_over3.pkl', 'wb') as f:\n",
    "#     pickle.dump(total_dict_over3, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./mimic-iv-data-nd/preprocessed_y_visit_over3.pkl', 'wb') as f:\n",
    "#     pickle.dump(save_y_dict, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_list = list()\n",
    "for p_key in tqdm(total_dict_over3.keys()):\n",
    "    label_list = save_y_dict[p_key]['top100_label']\n",
    "    top100_list.extend(list(set(label_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_count = dict(Counter(top100_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./diagnoses_top_100.pkl', 'wb') as f:\n",
    "    pickle.dump(top100_count, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_list = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./top_100_list.pkl', 'wb') as f:\n",
    "    pickle.dump(mlb_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
